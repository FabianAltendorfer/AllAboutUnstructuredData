{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install azure.ai.formrecognizer==3.2.0\r\n",
        "!pip install XlsxWriter==3.0.1 \r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "smpool2",
              "session_id": "7",
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-02-02T22:38:34.1224576Z",
              "session_start_time": "2023-02-02T22:38:34.1506191Z",
              "execution_start_time": "2023-02-02T22:41:04.6935827Z",
              "execution_finish_time": "2023-02-02T22:41:15.6216821Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(smpool2, 7, 1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure.ai.formrecognizer==3.2.0\n  Downloading azure_ai_formrecognizer-3.2.0-py3-none-any.whl (228 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.4/228.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: msrest>=0.6.21 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from azure.ai.formrecognizer==3.2.0) (0.7.1)\nRequirement already satisfied: azure-common~=1.1 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from azure.ai.formrecognizer==3.2.0) (1.1.28)\nRequirement already satisfied: typing-extensions>=4.0.1 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from azure.ai.formrecognizer==3.2.0) (4.4.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.23.0 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from azure.ai.formrecognizer==3.2.0) (1.26.1)\nRequirement already satisfied: requests>=2.18.4 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.23.0->azure.ai.formrecognizer==3.2.0) (2.28.1)\nRequirement already satisfied: six>=1.11.0 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.23.0->azure.ai.formrecognizer==3.2.0) (1.16.0)\nRequirement already satisfied: isodate>=0.6.0 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from msrest>=0.6.21->azure.ai.formrecognizer==3.2.0) (0.6.0)\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from msrest>=0.6.21->azure.ai.formrecognizer==3.2.0) (2022.9.24)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from msrest>=0.6.21->azure.ai.formrecognizer==3.2.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<3,>=2 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure.ai.formrecognizer==3.2.0) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure.ai.formrecognizer==3.2.0) (1.26.4)\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure.ai.formrecognizer==3.2.0) (3.4)\nRequirement already satisfied: oauthlib>=3.0.0 in /home/trusted-service-user/cluster-env/env/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure.ai.formrecognizer==3.2.0) (3.2.2)\nInstalling collected packages: azure.ai.formrecognizer\nSuccessfully installed azure.ai.formrecognizer-3.2.0\nCollecting XlsxWriter==3.0.1\n  Downloading XlsxWriter-3.0.1-py3-none-any.whl (148 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.7/148.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: XlsxWriter\nSuccessfully installed XlsxWriter-3.0.1\n"
          ]
        }
      ],
      "execution_count": 132,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\r\n",
        "from azure.storage.blob import generate_blob_sas, BlobSasPermissions\r\n",
        "from datetime import datetime, timedelta\r\n",
        "\r\n",
        "import logging\r\n",
        "import json\r\n",
        "import os\r\n",
        "import logging\r\n",
        "from datetime import datetime\r\n",
        "from json import JSONEncoder\r\n",
        "from azure.core.exceptions import ResourceNotFoundError\r\n",
        "from azure.core.credentials import AzureKeyCredential\r\n",
        "from azure.storage.blob import BlobServiceClient\r\n",
        "import pandas as pd\r\n",
        "import io\r\n",
        "from azure.ai.formrecognizer import DocumentAnalysisClient\r\n",
        "import urllib.parse\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "smpool2",
              "session_id": "7",
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-02-02T22:41:39.2901357Z",
              "session_start_time": null,
              "execution_start_time": "2023-02-02T22:41:39.4172765Z",
              "execution_finish_time": "2023-02-02T22:41:46.4319247Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(smpool2, 7, 2, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 133,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_blob_sas(storage_account_name, storage_account_key, storage_container_name, blob_name):\r\n",
        "    try:\r\n",
        "        #print(account_key)\r\n",
        "        sas_blob = generate_blob_sas(account_name= storage_account_name, \r\n",
        "                                    container_name= storage_container_name,\r\n",
        "                                    blob_name= blob_name,\r\n",
        "                                    account_key= storage_account_key,\r\n",
        "                                    permission= BlobSasPermissions(read=True),\r\n",
        "                                    start=datetime.utcnow(),\r\n",
        "                                    expiry=datetime.utcnow() + timedelta(hours=1))\r\n",
        "        return sas_blob\r\n",
        "    except Exception as e:\r\n",
        "        print(f'{get_blob_sas.__name__}: {str(e)}')\r\n",
        "\r\n",
        "def analyze_document( output_storage_acct, add_keyvalue_pairs, excel_output_folder, endpoint, key, formUrl ):\r\n",
        "    try:\r\n",
        "        parsed_url = urllib.parse.urlparse(formUrl)\r\n",
        "        full_file_name = parsed_url.path.split(\"/\")[-1]\r\n",
        "        filename = os.path.splitext(full_file_name)[0]\r\n",
        "\r\n",
        "        document_analysis_client = DocumentAnalysisClient(\r\n",
        "            endpoint=endpoint, credential=AzureKeyCredential(key)   \r\n",
        "        )\r\n",
        "        model=\"prebuilt-document\"\r\n",
        "        poller = document_analysis_client.begin_analyze_document_from_url(model,formUrl)\r\n",
        "        result = poller.result()\r\n",
        "\r\n",
        "        output_record = generate_excel(result,filename, output_storage_acct, excel_output_folder, add_keyvalue_pairs)\r\n",
        "        \r\n",
        "        \r\n",
        "\r\n",
        "    except Exception as error:\r\n",
        "        output_record =   \"Error: \" + str(error)\r\n",
        "        \r\n",
        "\r\n",
        "    logging.info(\"Output record: \" + output_record)\r\n",
        "    return output_record\r\n",
        "\r\n",
        "\r\n",
        "def generate_excel(result,filename, csvoutputstorage, csvoutputfolder, add_keyvalue_pairs):\r\n",
        "    if(add_keyvalue_pairs):\r\n",
        "        kvp=get_key_value_pairs(result)\r\n",
        "    formtables = {}\r\n",
        "    blob_service_client = BlobServiceClient.from_connection_string(csvoutputstorage)\r\n",
        "    container_client=blob_service_client.get_container_client(csvoutputfolder)\r\n",
        "    output = io.BytesIO()\r\n",
        "    writer = pd.ExcelWriter(output, engine='xlsxwriter')\r\n",
        "    workbook = writer.book\r\n",
        "    merge_format = workbook.add_format({'align': 'center', 'valign': 'vcenter', 'border': 2})\r\n",
        "\r\n",
        "    current_page_num=None\r\n",
        "    table_num=1\r\n",
        "    for table in result.tables:\r\n",
        "        column_row_spans = []\r\n",
        "        tableList = [[None for x in range(table.column_count)] for y in range(table.row_count)] \r\n",
        "\r\n",
        "        for cell in table.cells:\r\n",
        "            cellvalue=None\r\n",
        "            #only add the cell data if it has some alphanumeric text\r\n",
        "            if  (sum( c.isalnum() for c in cell.content) >0):\r\n",
        "                #replace selection marks data\r\n",
        "                cellvalue=cell.content.replace(\":unselected:\", \"\").replace(\":selected:\", \"\")\r\n",
        "                if(cell.row_span>1 and cell.column_span>1):\r\n",
        "                    column_row_spans.append([cell.row_index, cell.column_index, cell.row_index+cell.row_span-1,cell.column_index+cell.column_span-1, cellvalue ])\r\n",
        "                elif(cell.row_span>1 and cell.column_span==1):\r\n",
        "                    column_row_spans.append([cell.row_index, cell.column_index, cell.row_index+cell.row_span-1,cell.column_index, cellvalue ])\r\n",
        "                elif(cell.column_span>1 and cell.row_span==1):\r\n",
        "                    column_row_spans.append([cell.row_index, cell.column_index, cell.row_index,cell.column_index+cell.column_span-1, cellvalue ])\r\n",
        "                    \r\n",
        "            tableList[cell.row_index][cell.column_index] = cellvalue\r\n",
        "        \r\n",
        "        if current_page_num is None:\r\n",
        "            current_page_num = table.bounding_regions[0].page_number\r\n",
        "        elif (current_page_num is not None) and (current_page_num == table.bounding_regions[0].page_number):\r\n",
        "            table_num +=1\r\n",
        "        elif (current_page_num is not None) and (current_page_num != table.bounding_regions[0].page_number):\r\n",
        "            table_num =1\r\n",
        "            current_page_num = table.bounding_regions[0].page_number\r\n",
        "\r\n",
        "\r\n",
        "        excel_sheet_name=str(current_page_num) + '_' + str(table_num)\r\n",
        "        df = pd.DataFrame.from_records(tableList)\r\n",
        "        #set the header row\r\n",
        "        df.columns = df.iloc[0] \r\n",
        "        df = df[1:]\r\n",
        "        #remove empty rows\r\n",
        "        df = df[df.any(axis=1)]        \r\n",
        "        #write to excel only if dataframe has some data\r\n",
        "        if not(df.empty):\r\n",
        "            if(add_keyvalue_pairs and current_page_num in kvp ):\r\n",
        "                for key in kvp[current_page_num]:\r\n",
        "                    if not(key in df.columns ):\r\n",
        "                        df[key]= kvp[current_page_num][key]\r\n",
        "            df.to_excel(writer, sheet_name=excel_sheet_name, index=False)\r\n",
        "            worksheet = writer.sheets[excel_sheet_name]\r\n",
        "            if( len(column_row_spans) >0):  \r\n",
        "                for x in column_row_spans:\r\n",
        "                    worksheet.merge_range(x[0],x[1],x[2],x[3],x[4], merge_format)\r\n",
        "\r\n",
        "\r\n",
        "    #excel output\r\n",
        "    excelname=filename +'.xlsx'\r\n",
        "    writer.close()\r\n",
        "    logging.info(\"writing excel for : \" + excelname)\r\n",
        "    container_client.upload_blob(name=excelname,data=output.getvalue(),overwrite=True)\r\n",
        "\r\n",
        "    return 'Individual table per sheet has been generated sucecssfully in Excel:' +excelname\r\n",
        "\r\n",
        "\r\n",
        "def get_key_value_pairs(result):\r\n",
        "    kvp = {}\r\n",
        "    pagekvp = {}\r\n",
        "    pagelen= len(result.pages)\r\n",
        "    pagenum=None\r\n",
        "    currpagenum=None\r\n",
        "    for kv_pair in result.key_value_pairs:\r\n",
        "        if pagenum is None:\r\n",
        "            pagenum=kv_pair.key.bounding_regions[0].page_number\r\n",
        "        elif (pagenum is not None) and (pagenum != kv_pair.key.bounding_regions[0].page_number):\r\n",
        "            pagekvp[pagenum]=kvp\r\n",
        "            kvp = {}\r\n",
        "            pagenum=kv_pair.key.bounding_regions[0].page_number\r\n",
        "\r\n",
        "        if kv_pair.key:\r\n",
        "            if kv_pair.value:\r\n",
        "                kvp[kv_pair.key.content] = kv_pair.value.content\r\n",
        "    pagekvp[pagenum]=kvp\r\n",
        "    return pagekvp"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "smpool2",
              "session_id": "7",
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-02-02T22:41:48.2925045Z",
              "session_start_time": null,
              "execution_start_time": "2023-02-02T22:41:48.4109934Z",
              "execution_finish_time": "2023-02-02T22:41:48.58351Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(smpool2, 7, 3, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 134,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Requisites\r\n",
        "1. Create Form Recognizer Service\r\n",
        "2. Create Storage account and store the input forms \r\n",
        "3. Create Key Vault Serviceand confirgure with the following secrets\r\n",
        "    -  formrecogkey : Form Recogbizer Key\r\n",
        "    - formrecogurl  : Form Recogbizer End Point URL\r\n",
        "    - inputcontainerurl : URL of the Storage Container that has the forms data\r\n",
        "    - saconstr      : Connection String of the Storage account that has the forms data\r\n",
        "    - sakey         : Key of the Storage account that has the forms data\r\n",
        "\r\n",
        "Generated Excel spreagsheets are stored in folder specified in 'excel_output_folder'"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KEY_VAULT_NAME = '{Name of the Key Valut}'\r\n",
        "STORAGE_ACCOUNT_NAME = '{Name of the Storage Acct}'\r\n",
        "STORAGE_ACCOUNT_KEY = 'sakey'\r\n",
        "STORAGE_CONN_STRING = 'saconstr'\r\n",
        "FORMS_RECOGNIZER_URL_SECRET_NAME = 'formrecogurl'\r\n",
        "FORMS_RECOGNIZER_KEY_SECRET_NAME = 'formrecogkey'\r\n",
        "STORAGE_CONTAINER_URL ='inputcontainerurl'\r\n",
        "\r\n",
        "container_name = '{Name of the Container that has the input forms}'\r\n",
        "excel_output_folder =\"output/data\"\r\n",
        "add_keyvalue_pairs = False\r\n",
        "\r\n",
        "account_key = TokenLibrary.getSecret(f'{KEY_VAULT_NAME}.vault.usgovcloudapi.net', STORAGE_ACCOUNT_KEY, KEY_VAULT_NAME)\r\n",
        "print(account_key)\r\n",
        "\r\n",
        "storage_connection_string = TokenLibrary.getSecret(f'{KEY_VAULT_NAME}.vault.usgovcloudapi.net', STORAGE_CONN_STRING , KEY_VAULT_NAME)\r\n",
        "print(storage_connection_string)\r\n",
        "\r\n",
        "input_container_url = TokenLibrary.getSecret(f'{KEY_VAULT_NAME}.vault.usgovcloudapi.net', STORAGE_CONTAINER_URL , KEY_VAULT_NAME)\r\n",
        "print(input_container_url)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "frendpoint = TokenLibrary.getSecret(f'{KEY_VAULT_NAME}.vault.usgovcloudapi.net', FORMS_RECOGNIZER_URL_SECRET_NAME , KEY_VAULT_NAME)\r\n",
        "frkey = TokenLibrary.getSecret(f'{KEY_VAULT_NAME}.vault.usgovcloudapi.net', FORMS_RECOGNIZER_KEY_SECRET_NAME , KEY_VAULT_NAME)\r\n",
        "print(frendpoint)\r\n",
        "print(frkey)\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "smpool2",
              "session_id": "7",
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-02-02T22:42:15.8322869Z",
              "session_start_time": null,
              "execution_start_time": "2023-02-02T22:42:15.981143Z",
              "execution_finish_time": "2023-02-02T22:42:17.8664949Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(smpool2, 7, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PMK7CK0WoFJk9lBtUIhMt8tfN0UWq9rbBPyLnwCuvMTl7fuXrwLjhiq+11GDc6OPCoiE61c4a5Oq+ASt/tzbPw==\nDefaultEndpointsProtocol=https;AccountName=smformrecogsa;AccountKey=PMK7CK0WoFJk9lBtUIhMt8tfN0UWq9rbBPyLnwCuvMTl7fuXrwLjhiq+11GDc6OPCoiE61c4a5Oq+ASt/tzbPw==;EndpointSuffix=core.usgovcloudapi.net\nhttps://smformrecogsa.blob.core.usgovcloudapi.net/sample\nhttps://formrecogsm.cognitiveservices.azure.us/\n1f9a32bda21f4339b16c343a52fe2f83\n"
          ]
        }
      ],
      "execution_count": 135,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blob_service_client = BlobServiceClient.from_connection_string(storage_connection_string)\r\n",
        "container_client = blob_service_client.get_container_client(container_name)\r\n",
        "\r\n",
        "# List the blobs in the container\r\n",
        "blob_list = container_client.list_blobs()\r\n",
        "for blob in blob_list:\r\n",
        "    print(\"\\t\" + blob.name)\r\n",
        "\r\n",
        "    blob_sas = get_blob_sas(storage_account_name=STORAGE_ACCOUNT_NAME, storage_account_key=account_key, storage_container_name=container_name, blob_name=blob.name)\r\n",
        "    print(\"\\t blob_sas:\" + blob_sas)\r\n",
        "\r\n",
        "    blob_sas_url = f'{input_container_url}/{blob.name}?{blob_sas}'\r\n",
        "    print(\"\\t blob_sas_url:\" + blob_sas_url)\r\n",
        "\r\n",
        "\r\n",
        "    output_record = analyze_document( storage_connection_string, add_keyvalue_pairs, excel_output_folder,endpoint=frendpoint, key=frkey,  formUrl=blob_sas_url )  \r\n",
        "    \r\n",
        "    \r\n",
        "    print(output_record)\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "smpool2",
              "session_id": "7",
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-02-02T22:43:55.1763219Z",
              "session_start_time": null,
              "execution_start_time": "2023-02-02T22:43:55.3481363Z",
              "execution_finish_time": "2023-02-02T22:44:22.712329Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(smpool2, 7, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tAdatum 1.pdf\n\t blob_sas:st=2023-02-02T22%3A43%3A55Z&se=2023-02-02T23%3A43%3A55Z&sp=r&sv=2021-08-06&sr=b&sig=/8i7wKqQvfsorggs7%2BZG6DHikUyQMgna8IVPRNdfrns%3D\n\t blob_sas_url:https://smformrecogsa.blob.core.usgovcloudapi.net/sample/Adatum 1.pdf?st=2023-02-02T22%3A43%3A55Z&se=2023-02-02T23%3A43%3A55Z&sp=r&sv=2021-08-06&sr=b&sig=/8i7wKqQvfsorggs7%2BZG6DHikUyQMgna8IVPRNdfrns%3D\nIndividual table per sheet has been generated sucecssfully in Excel:Adatum 1.xlsx\n\tPurchaseOrderForm.pdf\n\t blob_sas:st=2023-02-02T22%3A44%3A00Z&se=2023-02-02T23%3A44%3A00Z&sp=r&sv=2021-08-06&sr=b&sig=sXjOOzVyif8DSlw7v19fOdw20DPnXEeFaA9jK29C9IU%3D\n\t blob_sas_url:https://smformrecogsa.blob.core.usgovcloudapi.net/sample/PurchaseOrderForm.pdf?st=2023-02-02T22%3A44%3A00Z&se=2023-02-02T23%3A44%3A00Z&sp=r&sv=2021-08-06&sr=b&sig=sXjOOzVyif8DSlw7v19fOdw20DPnXEeFaA9jK29C9IU%3D\nIndividual table per sheet has been generated sucecssfully in Excel:PurchaseOrderForm.xlsx\n\tearningreport.pdf\n\t blob_sas:st=2023-02-02T22%3A44%3A11Z&se=2023-02-02T23%3A44%3A11Z&sp=r&sv=2021-08-06&sr=b&sig=MJUeYPgLsYh02uB0MqbchBdzgwrBDmM6non5HKBkyHQ%3D\n\t blob_sas_url:https://smformrecogsa.blob.core.usgovcloudapi.net/sample/earningreport.pdf?st=2023-02-02T22%3A44%3A11Z&se=2023-02-02T23%3A44%3A11Z&sp=r&sv=2021-08-06&sr=b&sig=MJUeYPgLsYh02uB0MqbchBdzgwrBDmM6non5HKBkyHQ%3D\nIndividual table per sheet has been generated sucecssfully in Excel:earningreport.xlsx\n"
          ]
        }
      ],
      "execution_count": 137,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "END"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": false,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}